{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import importData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giuse\\OneDrive\\Documents\\GitHub\\ProgettoMachineLearning\\importData.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  _test = pd.read_csv(testPath, sep='\\s', header=None)\n",
      "c:\\Users\\giuse\\OneDrive\\Documents\\GitHub\\ProgettoMachineLearning\\importData.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  _train = pd.read_csv(trainPath, sep='\\s', header=None)\n",
      "c:\\Users\\giuse\\OneDrive\\Documents\\GitHub\\ProgettoMachineLearning\\importData.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  _test = pd.read_csv(testPath, sep='\\s', header=None)\n",
      "c:\\Users\\giuse\\OneDrive\\Documents\\GitHub\\ProgettoMachineLearning\\importData.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  _train = pd.read_csv(trainPath, sep='\\s', header=None)\n",
      "c:\\Users\\giuse\\OneDrive\\Documents\\GitHub\\ProgettoMachineLearning\\importData.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  _test = pd.read_csv(testPath, sep='\\s', header=None)\n",
      "c:\\Users\\giuse\\OneDrive\\Documents\\GitHub\\ProgettoMachineLearning\\importData.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  _train = pd.read_csv(trainPath, sep='\\s', header=None)\n"
     ]
    }
   ],
   "source": [
    "useTensor = False\n",
    "dataPath = \"C:\\\\Users\\\\giuse\\\\Downloads\\\\monk\\\\monks-\"\n",
    "monk1 = importData.importData(dataPath + \"1.train\", dataPath + \"1.test\", tensor=useTensor)\n",
    "monk2 = importData.importData(dataPath + \"2.train\", dataPath + \"2.test\", tensor=useTensor)\n",
    "monk3 = importData.importData(dataPath + \"3.train\", dataPath + \"3.test\", tensor=useTensor)\n",
    "\n",
    "algorithm = [\"lbfgs\", \"liblinear\", \"newton-cg\", \"sag\", \"saga\"]\n",
    "class_weight = [None, \"balanced\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in algorithm:\n",
    "    for weight in class_weight:\n",
    "        print(f\"algorithm={a}, class_weight={weight}, \")\n",
    "        model = LogisticRegression(solver=a, class_weight=weight)\n",
    "        model.fit(monk1.featuresTrain, monk1.labelTrain)\n",
    "        print(f\"Monk1: score = {model.score(monk1.featuresTest, monk1.labelTest)} \"\n",
    "            f\"log_loss = {log_loss(monk1.labelTest, model.predict_proba(monk1.featuresTest))}\")\n",
    "\n",
    "        model = LogisticRegression(solver=a, class_weight=weight)\n",
    "        model.fit(monk2.featuresTrain, monk2.labelTrain)\n",
    "        print(f\"Monk2: score = {model.score(monk2.featuresTest, monk2.labelTest)} \"\n",
    "            f\"log_loss = {log_loss(monk2.labelTest, model.predict_proba(monk2.featuresTest))}\")\n",
    "        \n",
    "        model = LogisticRegression(solver=a, class_weight=weight)\n",
    "        model.fit(monk3.featuresTrain, monk3.labelTrain)\n",
    "        print(f\"Monk3: score = {model.score(monk3.featuresTest, monk3.labelTest)} \"\n",
    "            f\"log_loss = {log_loss(monk3.labelTest, model.predict_proba(monk3.featuresTest))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm=lbfgs, class_weight=None, \n",
      "Monk1: score = 0.6612903225806451 log_loss = 0.6310203339110274\n",
      "Monk2: score = 0.621301775147929 log_loss = 0.6688842439019859\n",
      "Monk3: score = 0.7704918032786885 log_loss = 0.5480254272470778\n",
      "algorithm=lbfgs, class_weight=balanced, \n",
      "Monk1: score = 0.6612903225806451 log_loss = 0.6310203339110274\n",
      "Monk2: score = 0.5384615384615384 log_loss = 0.693055763266846\n",
      "Monk3: score = 0.7459016393442623 log_loss = 0.5453341759350502\n",
      "algorithm=liblinear, class_weight=None, \n",
      "Monk1: score = 0.6612903225806451 log_loss = 0.6910562890942161\n",
      "Monk2: score = 0.621301775147929 log_loss = 0.662749664080866\n",
      "Monk3: score = 0.7459016393442623 log_loss = 0.6882179595444315\n",
      "algorithm=liblinear, class_weight=balanced, \n",
      "Monk1: score = 0.6612903225806451 log_loss = 0.6910562890942161\n",
      "Monk2: score = 0.5266272189349113 log_loss = 0.6930687421110582\n",
      "Monk3: score = 0.7868852459016393 log_loss = 0.5452206406749412\n",
      "algorithm=newton-cg, class_weight=None, \n",
      "Monk1: score = 0.6612903225806451 log_loss = 0.6310277398802484\n",
      "Monk2: score = 0.621301775147929 log_loss = 0.6688801116325328\n",
      "Monk3: score = 0.7704918032786885 log_loss = 0.5480370294031599\n",
      "algorithm=newton-cg, class_weight=balanced, \n",
      "Monk1: score = 0.6612903225806451 log_loss = 0.6310277398802484\n",
      "Monk2: score = 0.5384615384615384 log_loss = 0.6930553474334537\n",
      "Monk3: score = 0.7459016393442623 log_loss = 0.545325158519652\n",
      "algorithm=sag, class_weight=None, \n",
      "Monk1: score = 0.6612903225806451 log_loss = 0.631020225159363\n",
      "Monk2: score = 0.621301775147929 log_loss = 0.6688786014364722\n",
      "Monk3: score = 0.7704918032786885 log_loss = 0.54801783731382\n",
      "algorithm=sag, class_weight=balanced, \n",
      "Monk1: score = 0.6612903225806451 log_loss = 0.6310204964904119\n",
      "Monk2: score = 0.5384615384615384 log_loss = 0.693057362319424\n",
      "Monk3: score = 0.7459016393442623 log_loss = 0.6586757933706412\n",
      "algorithm=saga, class_weight=None, \n",
      "Monk1: score = 0.6612903225806451 log_loss = 0.6310162499351398\n",
      "Monk2: score = 0.621301775147929 log_loss = 0.6688850933647309\n",
      "Monk3: score = 0.7704918032786885 log_loss = 0.5480356226268581\n",
      "algorithm=saga, class_weight=balanced, \n",
      "Monk1: score = 0.6612903225806451 log_loss = 0.6310201937033288\n",
      "Monk2: score = 0.5384615384615384 log_loss = 0.693054903700701\n",
      "Monk3: score = 0.7459016393442623 log_loss = 0.5453264938253628\n"
     ]
    }
   ],
   "source": [
    "for a in algorithm:\n",
    "    for weight in class_weight:\n",
    "        print(f\"algorithm={a}, class_weight={weight}, \")\n",
    "        model = LogisticRegressionCV(solver=a, class_weight=weight)\n",
    "        model.fit(monk1.featuresTrain, monk1.labelTrain)\n",
    "        print(f\"Monk1: score = {model.score(monk1.featuresTest, monk1.labelTest)} \"\n",
    "            f\"log_loss = {log_loss(monk1.labelTest, model.predict_proba(monk1.featuresTest))}\")\n",
    "\n",
    "        model = LogisticRegressionCV(solver=a, class_weight=weight)\n",
    "        model.fit(monk2.featuresTrain, monk2.labelTrain)\n",
    "        print(f\"Monk2: score = {model.score(monk2.featuresTest, monk2.labelTest)} \"\n",
    "            f\"log_loss = {log_loss(monk2.labelTest, model.predict_proba(monk2.featuresTest))}\")\n",
    "        \n",
    "        model = LogisticRegressionCV(solver=a, class_weight=weight)\n",
    "        model.fit(monk3.featuresTrain, monk3.labelTrain)\n",
    "        print(f\"Monk3: score = {model.score(monk3.featuresTest, monk3.labelTest)} \"\n",
    "            f\"log_loss = {log_loss(monk3.labelTest, model.predict_proba(monk3.featuresTest))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'Cs': 1, 'class_weight': None, 'cv': 3, 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "nJobs = 8\n",
    "linearRCV = LogisticRegressionCV()\n",
    "parameters = {'Cs': [1, 10, 100, 1000], 'cv': [3, 5, 10], \n",
    "              'solver': algorithm, 'class_weight': class_weight}\n",
    "classificators = GridSearchCV(linearRCV, parameters, n_jobs=nJobs)\n",
    "classificators.fit(monk1.featuresTrain, monk1.labelTrain)\n",
    "print(f\"Best parameters: {classificators.best_params_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
